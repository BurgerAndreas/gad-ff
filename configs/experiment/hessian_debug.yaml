# @package _global_

training:
  trn_path: "data/sample_100.lmdb"
  val_path: "data/sample_100.lmdb"
  bz: 2
  num_workers: 2  

# Pytorch Lightning Trainer configuration
pltrainer:
  # accelerator: "cpu"
  max_epochs: 2
  limit_train_batches: 2
  limit_val_batches: 2 

# model:
#   do_eigvec_2: false

use_wandb: false

experiment_name: "hessian_debug"
