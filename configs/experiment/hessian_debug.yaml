# @package _global_

training:
  trn_path: "data/sample_100.lmdb"
  val_path: "data/sample_100.lmdb"
  bz: 3
  num_workers: 2  

# Pytorch Lightning Trainer configuration
pltrainer:
  # accelerator: "cpu"
  max_epochs: 3
  limit_train_batches: 3
  limit_val_batches: 3

# model:
#   do_eigvec_2: false

use_wandb: false

experiment_name: "hessian_debug"
