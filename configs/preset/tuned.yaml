# @package _global_

model:
  alpha_drop:               0.0         # [0.0, 0.1]
  drop_path_rate:           0.0         # [0.0, 0.05]
  proj_drop:                0.0

training:
  hessian_loss_type: "mae"
  hessian_loss_weight: 10.0
  energy_loss_weight: 1.0
  force_loss_weight: 25.0

optimizer:
  amsgrad: False
  betas: [0.965, 0.965]
  lr: 0.00044
  weight_decay: 2e-05

pltrainer:
  gradient_clip_algorithm: norm
  gradient_clip_val: 7