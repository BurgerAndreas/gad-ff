{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Analysis of GAD Transition State Search Results\n",
        "\n",
        "This notebook loads and analyzes the results from `test_gad_ts_search` function, which tests GAD transition state optimization with different configurations:\n",
        "\n",
        "- **Eigen methods**: None, qr, svd, svdforce, inertia, geo, ase, eckartsvd, eckartqr\n",
        "- **Starting points**: Transition state, Perturbed TS, Reactant (various dt/steps), R-P interpolation, R-P geodesic interpolation\n",
        "- **Integration parameters**: Different dt values (0.01, 0.1) and max_steps (1000, 2000, 10000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configuration\n",
        "plots_dir = \"playground/plots_gad\"  # GAD plot directory\n",
        "logs_dir = \"playground/logs_gad\"    # GAD results directory\n",
        "print(f\"Looking for results in: {plots_dir}\")\n",
        "print(f\"Looking for logs in: {logs_dir}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Load All GAD Results Data\n",
        "\n",
        "Find all `summary.json` files in the plots directory and `results_*.json` files in the logs directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_gad_files(plots_dir, logs_dir):\n",
        "    \"\"\"Find all GAD result files in both directories\"\"\"\n",
        "    \n",
        "    # Find summary.json files from plots directory\n",
        "    summary_pattern = os.path.join(plots_dir, \"**/summary.json\")\n",
        "    summary_files = glob.glob(summary_pattern, recursive=True)\n",
        "    \n",
        "    # Find results_*.json files from logs directory  \n",
        "    results_pattern = os.path.join(logs_dir, \"results_*.json\")\n",
        "    results_files = glob.glob(results_pattern, recursive=True)\n",
        "    \n",
        "    print(f\"Found {len(summary_files)} summary.json files\")\n",
        "    print(f\"Found {len(results_files)} results_*.json files\")\n",
        "    \n",
        "    return summary_files, results_files\n",
        "\n",
        "def parse_gad_title(title):\n",
        "    \"\"\"Parse the GAD run title to extract key information\"\"\"\n",
        "    # Example titles: \n",
        "    # \"TS from TS qr idx104000\"\n",
        "    # \"TS from R svd idx104000\" \n",
        "    # \"TS from R-P interpolation inertia idx104000\"\n",
        "    \n",
        "    info = {\n",
        "        'starting_point': None,\n",
        "        'eigen_method': None,\n",
        "        'dt': None,\n",
        "        'max_steps': None,\n",
        "        'idx': None\n",
        "    }\n",
        "    \n",
        "    # Extract starting point\n",
        "    if \"from TS\" in title and \"perturbed\" not in title:\n",
        "        info['starting_point'] = \"TS\"\n",
        "    elif \"from perturbed TS\" in title:\n",
        "        info['starting_point'] = \"Perturbed TS\"\n",
        "    elif \"from R-P geodesic interpolation\" in title:\n",
        "        info['starting_point'] = \"R-P Geodesic\"\n",
        "    elif \"from R-P interpolation\" in title:\n",
        "        info['starting_point'] = \"R-P Linear\"\n",
        "    elif \"from R\" in title:\n",
        "        if \"10k steps\" in title:\n",
        "            info['starting_point'] = \"R (10k steps)\"\n",
        "        else:\n",
        "            info['starting_point'] = \"R\"\n",
        "    \n",
        "    # Extract index\n",
        "    idx_match = re.search(r'idx(\\d+)', title)\n",
        "    if idx_match:\n",
        "        info['idx'] = int(idx_match.group(1))\n",
        "    \n",
        "    # Extract eigen method - look for known methods\n",
        "    eigen_methods = [\"qr\", \"svd\", \"svdforce\", \"inertia\", \"geo\", \"ase\", \"eckartsvd\", \"eckartqr\", \"None\"]\n",
        "    for method in eigen_methods:\n",
        "        if f\" {method} \" in title or title.endswith(f\" {method}\"):\n",
        "            info['eigen_method'] = method\n",
        "            break\n",
        "    \n",
        "    return info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_results_filename(filename):\n",
        "    \"\"\"Parse results_*.json filename to extract eigen method and idx\"\"\"\n",
        "    # Example: \"results_qr_idx104000.json\"\n",
        "    basename = os.path.basename(filename)\n",
        "    \n",
        "    info = {\n",
        "        'eigen_method': None,\n",
        "        'idx': None\n",
        "    }\n",
        "    \n",
        "    # Extract eigen method and idx\n",
        "    match = re.search(r'results_([^_]+)_idx(\\d+)\\.json', basename)\n",
        "    if match:\n",
        "        info['eigen_method'] = match.group(1)\n",
        "        info['idx'] = int(match.group(2))\n",
        "    \n",
        "    return info\n",
        "\n",
        "def load_gad_data(summary_files, results_files):\n",
        "    \"\"\"Load all GAD data into a comprehensive dataset\"\"\"\n",
        "    data = []\n",
        "    \n",
        "    # Load summary files (from trajectory integration)\n",
        "    for file_path in summary_files:\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                summary = json.load(f)\n",
        "            \n",
        "            # Extract directory name which contains the title\n",
        "            dir_name = os.path.basename(os.path.dirname(file_path))\n",
        "            \n",
        "            # Parse title information\n",
        "            title_info = parse_gad_title(dir_name)\n",
        "            \n",
        "            # Combine summary data with parsed title info\n",
        "            row = {\n",
        "                'source': 'summary',\n",
        "                'file_path': file_path,\n",
        "                'directory': dir_name,\n",
        "                **title_info,\n",
        "                **summary\n",
        "            }\n",
        "            \n",
        "            data.append(row)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path}: {e}\")\n",
        "    \n",
        "    # Load results files (from GAD specific results)\n",
        "    for file_path in results_files:\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                results = json.load(f)\n",
        "            \n",
        "            # Parse filename info\n",
        "            file_info = parse_results_filename(file_path)\n",
        "            \n",
        "            # Create separate rows for each test scenario\n",
        "            for test_name, rmsd_value in results.items():\n",
        "                # Parse test name to extract starting point info\n",
        "                test_info = {\n",
        "                    'starting_point': None,\n",
        "                    'dt': None,\n",
        "                    'max_steps': None\n",
        "                }\n",
        "                \n",
        "                if \"ts_from_ts\" in test_name:\n",
        "                    test_info['starting_point'] = \"TS\"\n",
        "                elif \"ts_from_perturbed_ts\" in test_name:\n",
        "                    test_info['starting_point'] = \"Perturbed TS\"\n",
        "                elif \"ts_from_r_p_geo\" in test_name:\n",
        "                    test_info['starting_point'] = \"R-P Geodesic\"\n",
        "                elif \"ts_from_r_p\" in test_name:\n",
        "                    test_info['starting_point'] = \"R-P Linear\"\n",
        "                elif \"ts_from_r\" in test_name:\n",
        "                    if \"s10000\" in test_name:\n",
        "                        test_info['starting_point'] = \"R (10k steps)\"\n",
        "                        test_info['max_steps'] = 10000\n",
        "                    else:\n",
        "                        test_info['starting_point'] = \"R\"\n",
        "                \n",
        "                # Extract dt and steps from test name\n",
        "                if \"dt0.01\" in test_name:\n",
        "                    test_info['dt'] = 0.01\n",
        "                elif \"dt0.1\" in test_name:\n",
        "                    test_info['dt'] = 0.1\n",
        "                \n",
        "                if \"s1000\" in test_name and \"s10000\" not in test_name:\n",
        "                    test_info['max_steps'] = 1000\n",
        "                elif \"s2000\" in test_name:\n",
        "                    test_info['max_steps'] = 2000\n",
        "                \n",
        "                row = {\n",
        "                    'source': 'results',\n",
        "                    'file_path': file_path,\n",
        "                    'test_name': test_name,\n",
        "                    'rmsd_final': rmsd_value,\n",
        "                    **file_info,\n",
        "                    **test_info\n",
        "                }\n",
        "                \n",
        "                data.append(row)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path}: {e}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Load all data\n",
        "summary_files, results_files = find_gad_files(plots_dir, logs_dir)\n",
        "if len(summary_files) == 0 and len(results_files) == 0:\n",
        "    print(f\"No GAD result files found in {plots_dir} or {logs_dir}\")\n",
        "    print(\"Make sure you've run the GAD tests first with --do-gad flag\")\n",
        "else:\n",
        "    data = load_gad_data(summary_files, results_files)\n",
        "    df = pd.DataFrame(data)\n",
        "    print(f\"Loaded {len(df)} GAD runs into DataFrame\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Explore the GAD Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(summary_files) > 0 or len(results_files) > 0:\n",
        "    print(\"DataFrame shape:\", df.shape)\n",
        "    print(\"\\nColumns:\", list(df.columns))\n",
        "    \n",
        "    print(\"\\nData sources:\", df['source'].value_counts())\n",
        "    print(\"\\nStarting points:\", df['starting_point'].value_counts())\n",
        "    print(\"\\nEigen methods:\", df['eigen_method'].value_counts())\n",
        "    \n",
        "    # Check for key metrics\n",
        "    key_metrics = ['rmsd_final', 'rmsd_initial', 'rmsd_improvement', 'nsteps', 'time_taken', 'dt', 'max_steps']\n",
        "    available_metrics = [col for col in key_metrics if col in df.columns]\n",
        "    print(f\"\\nAvailable metrics: {available_metrics}\")\n",
        "    \n",
        "    # Show first few rows\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    display_cols = ['source', 'starting_point', 'eigen_method', 'dt', 'max_steps'] + [col for col in ['rmsd_final', 'nsteps', 'time_taken'] if col in df.columns]\n",
        "    display_cols = [col for col in display_cols if col in df.columns]\n",
        "    print(df[display_cols].head(10))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Cleaning and Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(summary_files) > 0 or len(results_files) > 0:\n",
        "    # Clean the data\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Handle missing values in key columns\n",
        "    if 'rmsd_final' in df_clean.columns:\n",
        "        print(f\"Rows with missing rmsd_final: {df_clean['rmsd_final'].isna().sum()}\")\n",
        "        \n",
        "    # Create a combined identifier for eigen method and starting point\n",
        "    df_clean['eigen_start'] = df_clean['eigen_method'].astype(str) + \" + \" + df_clean['starting_point'].astype(str)\n",
        "    \n",
        "    # Create a method identifier that includes integration parameters when available\n",
        "    df_clean['method_full'] = df_clean['eigen_method'].astype(str)\n",
        "    \n",
        "    # Add dt and max_steps info when available\n",
        "    dt_mask = df_clean['dt'].notna()\n",
        "    steps_mask = df_clean['max_steps'].notna()\n",
        "    \n",
        "    df_clean.loc[dt_mask, 'method_full'] = df_clean.loc[dt_mask, 'method_full'] + \" (dt=\" + df_clean.loc[dt_mask, 'dt'].astype(str) + \")\"\n",
        "    df_clean.loc[steps_mask, 'method_full'] = df_clean.loc[steps_mask, 'method_full'] + \" (steps=\" + df_clean.loc[steps_mask, 'max_steps'].astype(str) + \")\"\n",
        "    \n",
        "    print(f\"\\nCleaned DataFrame shape: {df_clean.shape}\")\n",
        "    print(f\"\\nEigen + Starting point combinations:\")\n",
        "    print(df_clean['eigen_start'].value_counts().head(10))\n",
        "    \n",
        "    print(f\"\\nFull method combinations (top 15):\")\n",
        "    print(df_clean['method_full'].value_counts().head(15))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Main Plot: RMSD by Eigen Method and Starting Point\n",
        "\n",
        "Create comprehensive plots showing final RMSD grouped by eigen method and starting point.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (len(summary_files) > 0 or len(results_files) > 0) and 'rmsd_final' in df_clean.columns:\n",
        "    # Filter out rows with missing rmsd_final\n",
        "    df_plot = df_clean.dropna(subset=['rmsd_final', 'starting_point', 'eigen_method'])\n",
        "    \n",
        "    if len(df_plot) == 0:\n",
        "        print(\"No valid data for plotting\")\n",
        "    else:\n",
        "        # Create the main plot\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
        "        fig.suptitle('GAD Transition State Search Results: Final RMSD Analysis', fontsize=16, fontweight='bold')\n",
        "        \n",
        "        # Plot 1: Box plot by starting point and eigen method\n",
        "        ax1 = axes[0, 0]\n",
        "        sns.boxplot(data=df_plot, x='starting_point', y='rmsd_final', hue='eigen_method', ax=ax1)\n",
        "        ax1.set_title('Final RMSD by Starting Point and Eigen Method')\n",
        "        ax1.set_ylabel('Final RMSD (Ã…)')\n",
        "        ax1.tick_params(axis='x', rotation=45)\n",
        "        ax1.legend(title='Eigen Method', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        \n",
        "        # Plot 2: Box plot by eigen method only\n",
        "        ax2 = axes[0, 1]\n",
        "        sns.boxplot(data=df_plot, x='eigen_method', y='rmsd_final', ax=ax2)\n",
        "        ax2.set_title('Final RMSD by Eigen Method')\n",
        "        ax2.set_ylabel('Final RMSD (Ã…)')\n",
        "        ax2.tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Plot 3: Violin plot showing distribution\n",
        "        ax3 = axes[1, 0]\n",
        "        if len(df_plot['starting_point'].unique()) <= 10:  # Only if not too many categories\n",
        "            sns.violinplot(data=df_plot, x='starting_point', y='rmsd_final', ax=ax3)\n",
        "            ax3.set_title('Final RMSD Distribution by Starting Point')\n",
        "            ax3.set_ylabel('Final RMSD (Ã…)')\n",
        "            ax3.tick_params(axis='x', rotation=45)\n",
        "        else:\n",
        "            ax3.text(0.5, 0.5, 'Too many starting point categories for violin plot', \n",
        "                    ha='center', va='center', transform=ax3.transAxes)\n",
        "            ax3.set_title('Starting Point Categories Too Numerous')\n",
        "        \n",
        "        # Plot 4: Scatter plot of performance (if nsteps available)\n",
        "        ax4 = axes[1, 1]\n",
        "        if 'nsteps' in df_plot.columns and df_plot['nsteps'].notna().sum() > 0:\n",
        "            scatter = sns.scatterplot(data=df_plot, x='nsteps', y='rmsd_final', \n",
        "                                    hue='starting_point', style='eigen_method', \n",
        "                                    s=100, ax=ax4)\n",
        "            ax4.set_title('Final RMSD vs Number of Integration Steps')\n",
        "            ax4.set_xlabel('Number of Integration Steps')\n",
        "            ax4.set_ylabel('Final RMSD (Ã…)')\n",
        "            ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        else:\n",
        "            # Alternative plot with dt vs rmsd if available\n",
        "            if 'dt' in df_plot.columns and df_plot['dt'].notna().sum() > 0:\n",
        "                sns.scatterplot(data=df_plot, x='dt', y='rmsd_final', \n",
        "                              hue='starting_point', style='eigen_method', \n",
        "                              s=100, ax=ax4)\n",
        "                ax4.set_title('Final RMSD vs Integration Time Step')\n",
        "                ax4.set_xlabel('Time Step (dt)')\n",
        "                ax4.set_ylabel('Final RMSD (Ã…)')\n",
        "                ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "            else:\n",
        "                ax4.text(0.5, 0.5, 'Integration step data not available', \n",
        "                        ha='center', va='center', transform=ax4.transAxes)\n",
        "                ax4.set_title('Integration Data Not Available')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print summary statistics\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"GAD SUMMARY STATISTICS\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        print(\"\\nFinal RMSD by Starting Point:\")\n",
        "        print(df_plot.groupby('starting_point')['rmsd_final'].describe())\n",
        "        \n",
        "        print(\"\\nFinal RMSD by Eigen Method:\")\n",
        "        print(df_plot.groupby('eigen_method')['rmsd_final'].describe())\n",
        "        \n",
        "        # Best performing configurations\n",
        "        print(\"\\nBest performing configurations (lowest final RMSD):\")\n",
        "        best_cols = ['starting_point', 'eigen_method', 'dt', 'max_steps', 'rmsd_final']\n",
        "        if 'nsteps' in df_plot.columns:\n",
        "            best_cols.append('nsteps')\n",
        "        best_cols = [col for col in best_cols if col in df_plot.columns]\n",
        "        \n",
        "        best_configs = df_plot.nsmallest(15, 'rmsd_final')[best_cols]\n",
        "        print(best_configs.to_string(index=False))\n",
        "        \n",
        "        # Worst performing configurations\n",
        "        print(\"\\nWorst performing configurations (highest final RMSD):\")\n",
        "        worst_configs = df_plot.nlargest(10, 'rmsd_final')[best_cols]\n",
        "        print(worst_configs.to_string(index=False))\n",
        "        \n",
        "else:\n",
        "    print(\"No data available for plotting. Make sure GAD runs have been completed.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Additional Analysis: Eigen Method Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (len(summary_files) > 0 or len(results_files) > 0) and 'rmsd_final' in df_clean.columns:\n",
        "    df_eigen = df_clean.dropna(subset=['rmsd_final', 'eigen_method'])\n",
        "    \n",
        "    if len(df_eigen) > 0:\n",
        "        # Detailed eigen method analysis\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
        "        fig.suptitle('GAD Eigen Method Detailed Analysis', fontsize=16, fontweight='bold')\n",
        "        \n",
        "        # Plot 1: Box plot of RMSD by eigen method\n",
        "        ax1 = axes[0, 0]\n",
        "        eigen_order = df_eigen.groupby('eigen_method')['rmsd_final'].median().sort_values().index\n",
        "        sns.boxplot(data=df_eigen, x='eigen_method', y='rmsd_final', order=eigen_order, ax=ax1)\n",
        "        ax1.set_title('Final RMSD by Eigen Method (sorted by median)')\n",
        "        ax1.set_ylabel('Final RMSD (Ã…)')\n",
        "        ax1.tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Plot 2: Success rate (RMSD < threshold)\n",
        "        ax2 = axes[0, 1]\n",
        "        threshold = 0.1  # 0.1 Ã… threshold for \"success\"\n",
        "        success_rate = df_eigen.groupby('eigen_method').apply(\n",
        "            lambda x: (x['rmsd_final'] < threshold).mean() * 100\n",
        "        ).sort_values(ascending=False)\n",
        "        \n",
        "        success_rate.plot(kind='bar', ax=ax2)\n",
        "        ax2.set_title(f'Success Rate by Eigen Method (RMSD < {threshold} Ã…)')\n",
        "        ax2.set_ylabel('Success Rate (%)')\n",
        "        ax2.tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Plot 3: Performance by starting point for each eigen method\n",
        "        ax3 = axes[1, 0]\n",
        "        if len(df_eigen['starting_point'].unique()) <= 8:  # Only if manageable number\n",
        "            pivot_data = df_eigen.pivot_table(values='rmsd_final', \n",
        "                                             index='eigen_method', \n",
        "                                             columns='starting_point', \n",
        "                                             aggfunc='mean')\n",
        "            sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='RdYlBu_r', ax=ax3)\n",
        "            ax3.set_title('Mean Final RMSD Heatmap')\n",
        "            ax3.set_xlabel('Starting Point')\n",
        "            ax3.set_ylabel('Eigen Method')\n",
        "        else:\n",
        "            ax3.text(0.5, 0.5, 'Too many starting points for heatmap', \n",
        "                    ha='center', va='center', transform=ax3.transAxes)\n",
        "            ax3.set_title('Too Many Categories for Heatmap')\n",
        "        \n",
        "        # Plot 4: Distribution comparison\n",
        "        ax4 = axes[1, 1]\n",
        "        top_methods = df_eigen['eigen_method'].value_counts().head(6).index\n",
        "        df_top = df_eigen[df_eigen['eigen_method'].isin(top_methods)]\n",
        "        \n",
        "        for method in top_methods:\n",
        "            method_data = df_top[df_top['eigen_method'] == method]['rmsd_final']\n",
        "            ax4.hist(method_data, alpha=0.6, label=method, bins=20)\n",
        "        \n",
        "        ax4.set_title('RMSD Distribution by Top Eigen Methods')\n",
        "        ax4.set_xlabel('Final RMSD (Ã…)')\n",
        "        ax4.set_ylabel('Frequency')\n",
        "        ax4.legend()\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print statistical summary\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"EIGEN METHOD STATISTICAL ANALYSIS\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        print(f\"\\nSuccess rates (RMSD < {threshold} Ã…):\")\n",
        "        for method, rate in success_rate.items():\n",
        "            print(f\"{method:12s}: {rate:6.1f}%\")\n",
        "        \n",
        "        print(\"\\nMedian RMSD by eigen method:\")\n",
        "        median_rmsd = df_eigen.groupby('eigen_method')['rmsd_final'].median().sort_values()\n",
        "        for method, rmsd in median_rmsd.items():\n",
        "            print(f\"{method:12s}: {rmsd:7.4f} Ã…\")\n",
        "            \n",
        "    else:\n",
        "        print(\"No valid eigen method data for analysis\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Integration Parameter Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (len(summary_files) > 0 or len(results_files) > 0):\n",
        "    # Analyze integration parameters (dt, max_steps) if available\n",
        "    param_cols = ['dt', 'max_steps']\n",
        "    available_params = [col for col in param_cols if col in df_clean.columns and df_clean[col].notna().sum() > 0]\n",
        "    \n",
        "    if available_params and 'rmsd_final' in df_clean.columns:\n",
        "        df_params = df_clean.dropna(subset=['rmsd_final'] + available_params)\n",
        "        \n",
        "        if len(df_params) > 0:\n",
        "            n_params = len(available_params)\n",
        "            fig, axes = plt.subplots(1, n_params, figsize=(8*n_params, 6))\n",
        "            if n_params == 1:\n",
        "                axes = [axes]\n",
        "            \n",
        "            fig.suptitle('GAD Integration Parameter Analysis', fontsize=16, fontweight='bold')\n",
        "            \n",
        "            for i, param in enumerate(available_params):\n",
        "                df_param = df_params.dropna(subset=[param])\n",
        "                \n",
        "                if len(df_param) > 0:\n",
        "                    if param == 'dt':\n",
        "                        # For dt, use scatter plot\n",
        "                        sns.scatterplot(data=df_param, x=param, y='rmsd_final', \n",
        "                                      hue='starting_point', style='eigen_method',\n",
        "                                      s=100, ax=axes[i])\n",
        "                        axes[i].set_title(f'Final RMSD vs {param}')\n",
        "                        axes[i].set_xlabel(f'{param}')\n",
        "                        axes[i].set_ylabel('Final RMSD (Ã…)')\n",
        "                    else:\n",
        "                        # For max_steps, use box plot\n",
        "                        sns.boxplot(data=df_param, x=param, y='rmsd_final', ax=axes[i])\n",
        "                        axes[i].set_title(f'Final RMSD vs {param}')\n",
        "                        axes[i].set_xlabel(f'{param}')\n",
        "                        axes[i].set_ylabel('Final RMSD (Ã…)')\n",
        "                        axes[i].tick_params(axis='x', rotation=45)\n",
        "                    \n",
        "                    if i > 0:  # Remove legend from subsequent plots\n",
        "                        legend = axes[i].get_legend()\n",
        "                        if legend:\n",
        "                            legend.remove()\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            # Print parameter analysis\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"INTEGRATION PARAMETER ANALYSIS\")\n",
        "            print(\"=\"*60)\n",
        "            \n",
        "            for param in available_params:\n",
        "                df_param = df_params.dropna(subset=[param])\n",
        "                if len(df_param) > 0:\n",
        "                    print(f\"\\nFinal RMSD by {param}:\")\n",
        "                    print(df_param.groupby(param)['rmsd_final'].describe())\n",
        "    \n",
        "    # Time analysis if available\n",
        "    if 'time_taken' in df_clean.columns and df_clean['time_taken'].notna().sum() > 0:\n",
        "        df_time = df_clean.dropna(subset=['time_taken', 'rmsd_final'])\n",
        "        \n",
        "        if len(df_time) > 0:\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "            fig.suptitle('GAD Computational Performance Analysis', fontsize=16, fontweight='bold')\n",
        "            \n",
        "            # Time vs RMSD\n",
        "            sns.scatterplot(data=df_time, x='time_taken', y='rmsd_final', \n",
        "                          hue='eigen_method', style='starting_point', \n",
        "                          s=100, ax=axes[0])\n",
        "            axes[0].set_title('Final RMSD vs Computation Time')\n",
        "            axes[0].set_xlabel('Time Taken (s)')\n",
        "            axes[0].set_ylabel('Final RMSD (Ã…)')\n",
        "            \n",
        "            # Time by eigen method\n",
        "            sns.boxplot(data=df_time, x='eigen_method', y='time_taken', ax=axes[1])\n",
        "            axes[1].set_title('Computation Time by Eigen Method')\n",
        "            axes[1].set_xlabel('Eigen Method')\n",
        "            axes[1].set_ylabel('Time Taken (s)')\n",
        "            axes[1].tick_params(axis='x', rotation=45)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            print(\"\\nComputation time by eigen method:\")\n",
        "            print(df_time.groupby('eigen_method')['time_taken'].describe())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Export Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to save results\n",
        "# if len(summary_files) > 0 or len(results_files) > 0:\n",
        "#     # Save the cleaned dataframe\n",
        "#     output_file = \"gad_results_analysis.csv\"\n",
        "#     df_clean.to_csv(output_file, index=False)\n",
        "#     print(f\"Saved cleaned results to {output_file}\")\n",
        "    \n",
        "#     # Save summary statistics\n",
        "#     summary_stats = {\n",
        "#         'total_runs': len(df_clean),\n",
        "#         'successful_runs': len(df_clean.dropna(subset=['rmsd_final'])),\n",
        "#         'starting_points': df_clean['starting_point'].value_counts().to_dict(),\n",
        "#         'eigen_methods': df_clean['eigen_method'].value_counts().to_dict(),\n",
        "#         'data_sources': df_clean['source'].value_counts().to_dict()\n",
        "#     }\n",
        "    \n",
        "#     with open('gad_results_summary.json', 'w') as f:\n",
        "#         json.dump(summary_stats, f, indent=2)\n",
        "    \n",
        "#     print(f\"Saved summary statistics to gad_results_summary.json\")\n",
        "#     print(f\"\\nAnalysis complete! Processed {len(df_clean)} GAD optimization runs.\")\n",
        "# else:\n",
        "#     print(\"No data to export. Run GAD optimization first.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GAD RESULTS ANALYSIS COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "if len(summary_files) > 0 or len(results_files) > 0:\n",
        "    print(f\"Successfully analyzed {len(df)} GAD transition state search results.\")\n",
        "    print(\"\\nKey findings:\")\n",
        "    if 'rmsd_final' in df_clean.columns:\n",
        "        df_valid = df_clean.dropna(subset=['rmsd_final'])\n",
        "        if len(df_valid) > 0:\n",
        "            print(f\"- Total valid runs: {len(df_valid)}\")\n",
        "            print(f\"- Best RMSD achieved: {df_valid['rmsd_final'].min():.4f} Ã…\")\n",
        "            print(f\"- Median RMSD: {df_valid['rmsd_final'].median():.4f} Ã…\")\n",
        "            if 'eigen_method' in df_valid.columns:\n",
        "                best_method = df_valid.loc[df_valid['rmsd_final'].idxmin(), 'eigen_method']\n",
        "                print(f\"- Best performing eigen method: {best_method}\")\n",
        "else:\n",
        "    print(\"No GAD results found. Please run GAD tests first with --do-gad flag.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Recommended Analysis Plots\n",
        "\n",
        "### Primary Analysis: Core Algorithmic Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (len(summary_files) > 0 or len(results_files) > 0) and 'rmsd_final' in df_clean.columns:\n",
        "    df_analysis = df_clean.dropna(subset=['rmsd_final', 'eigen_method'])\n",
        "    \n",
        "    if len(df_analysis) > 0:\n",
        "        # PRIMARY ANALYSIS PLOTS\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
        "        fig.suptitle('GAD Primary Analysis: Core Performance Metrics', fontsize=18, fontweight='bold')\n",
        "        \n",
        "        # 1. Eigen Method Performance (sorted by median)\n",
        "        ax1 = axes[0, 0]\n",
        "        eigen_order = df_analysis.groupby('eigen_method')['rmsd_final'].median().sort_values().index\n",
        "        sns.boxplot(data=df_analysis, x='eigen_method', y='rmsd_final', order=eigen_order, ax=ax1)\n",
        "        ax1.set_title('1. RMSD by Eigen Method (sorted by median performance)', fontweight='bold')\n",
        "        ax1.set_ylabel('Final RMSD (Ã…)')\n",
        "        ax1.tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Add median values as text\n",
        "        medians = df_analysis.groupby('eigen_method')['rmsd_final'].median()\n",
        "        for i, method in enumerate(eigen_order):\n",
        "            ax1.text(i, medians[method] + 0.01, f'{medians[method]:.3f}', \n",
        "                    ha='center', va='bottom', fontweight='bold')\n",
        "        \n",
        "        # 2. Success Rate by Eigen Method\n",
        "        ax2 = axes[0, 1]\n",
        "        threshold = 0.1  # Success threshold\n",
        "        success_rate = df_analysis.groupby('eigen_method').apply(\n",
        "            lambda x: (x['rmsd_final'] < threshold).mean() * 100\n",
        "        ).sort_values(ascending=False)\n",
        "        \n",
        "        success_rate.plot(kind='bar', ax=ax2, color='skyblue', alpha=0.8)\n",
        "        ax2.set_title(f'2. Success Rate by Eigen Method (RMSD < {threshold} Ã…)', fontweight='bold')\n",
        "        ax2.set_ylabel('Success Rate (%)')\n",
        "        ax2.tick_params(axis='x', rotation=45)\n",
        "        ax2.set_ylim(0, 100)\n",
        "        \n",
        "        # Add percentage labels on bars\n",
        "        for i, (method, rate) in enumerate(success_rate.items()):\n",
        "            ax2.text(i, rate + 1, f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "        \n",
        "        # 3. Starting Point Reliability\n",
        "        ax3 = axes[1, 0]\n",
        "        if 'starting_point' in df_analysis.columns and df_analysis['starting_point'].notna().sum() > 0:\n",
        "            df_start = df_analysis.dropna(subset=['starting_point'])\n",
        "            sns.boxplot(data=df_start, x='starting_point', y='rmsd_final', hue='eigen_method', ax=ax3)\n",
        "            ax3.set_title('3. RMSD by Starting Point and Eigen Method', fontweight='bold')\n",
        "            ax3.set_ylabel('Final RMSD (Ã…)')\n",
        "            ax3.tick_params(axis='x', rotation=45)\n",
        "            ax3.legend(title='Eigen Method', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        else:\n",
        "            ax3.text(0.5, 0.5, 'Starting point data not available', \n",
        "                    ha='center', va='center', transform=ax3.transAxes)\n",
        "            ax3.set_title('3. Starting Point Analysis - Data Not Available')\n",
        "        \n",
        "        # 4. Distribution Comparison (Top Methods)\n",
        "        ax4 = axes[1, 1]\n",
        "        top_methods = df_analysis['eigen_method'].value_counts().head(5).index\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, len(top_methods)))\n",
        "        \n",
        "        for i, method in enumerate(top_methods):\n",
        "            method_data = df_analysis[df_analysis['eigen_method'] == method]['rmsd_final']\n",
        "            if len(method_data) > 0:\n",
        "                ax4.hist(method_data, alpha=0.7, label=f'{method} (n={len(method_data)})', \n",
        "                        bins=15, color=colors[i])\n",
        "        \n",
        "        ax4.set_title('4. RMSD Distribution by Top Eigen Methods', fontweight='bold')\n",
        "        ax4.set_xlabel('Final RMSD (Ã…)')\n",
        "        ax4.set_ylabel('Frequency')\n",
        "        ax4.legend()\n",
        "        ax4.axvline(x=threshold, color='red', linestyle='--', alpha=0.7, \n",
        "                   label=f'Success threshold ({threshold} Ã…)')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print key insights\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"KEY INSIGHTS FROM PRIMARY ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        print(f\"\\nðŸ“Š BEST PERFORMING EIGEN METHODS (by median RMSD):\")\n",
        "        for i, (method, median_rmsd) in enumerate(medians.sort_values().head(3).items()):\n",
        "            success_pct = success_rate[method] if method in success_rate.index else 0\n",
        "            print(f\"  {i+1}. {method:12s}: {median_rmsd:.4f} Ã… (success: {success_pct:.1f}%)\")\n",
        "        \n",
        "        print(f\"\\nðŸŽ¯ MOST RELIABLE METHODS (by success rate):\")\n",
        "        for i, (method, rate) in enumerate(success_rate.head(3).items()):\n",
        "            median_rmsd = medians[method] if method in medians.index else float('inf')\n",
        "            print(f\"  {i+1}. {method:12s}: {rate:.1f}% success (median: {median_rmsd:.4f} Ã…)\")\n",
        "        \n",
        "        print(f\"\\nðŸ“ˆ PERFORMANCE SUMMARY:\")\n",
        "        print(f\"  â€¢ Total runs analyzed: {len(df_analysis)}\")\n",
        "        print(f\"  â€¢ Overall success rate: {(df_analysis['rmsd_final'] < threshold).mean()*100:.1f}%\")\n",
        "        print(f\"  â€¢ Best RMSD achieved: {df_analysis['rmsd_final'].min():.4f} Ã…\")\n",
        "        print(f\"  â€¢ Median RMSD overall: {df_analysis['rmsd_final'].median():.4f} Ã…\")\n",
        "    \n",
        "    else:\n",
        "        print(\"No valid data for primary analysis plots\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Secondary Analysis: Deep Insights and Interactions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (len(summary_files) > 0 or len(results_files) > 0) and 'rmsd_final' in df_clean.columns:\n",
        "    df_secondary = df_clean.dropna(subset=['rmsd_final'])\n",
        "    \n",
        "    if len(df_secondary) > 0:\n",
        "        # SECONDARY ANALYSIS PLOTS\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(22, 16))\n",
        "        fig.suptitle('GAD Secondary Analysis: Interaction Effects & Optimization', fontsize=18, fontweight='bold')\n",
        "        \n",
        "        # 1. Method Ã— Starting Point Heatmap\n",
        "        ax1 = axes[0, 0]\n",
        "        if ('eigen_method' in df_secondary.columns and 'starting_point' in df_secondary.columns and \n",
        "            df_secondary[['eigen_method', 'starting_point']].notna().all(axis=1).sum() > 0):\n",
        "            \n",
        "            df_heatmap = df_secondary.dropna(subset=['eigen_method', 'starting_point'])\n",
        "            \n",
        "            # Only create heatmap if we have reasonable number of categories\n",
        "            n_eigen = df_heatmap['eigen_method'].nunique()\n",
        "            n_start = df_heatmap['starting_point'].nunique()\n",
        "            \n",
        "            if n_eigen <= 12 and n_start <= 10:  # Reasonable limits for heatmap\n",
        "                pivot_table = df_heatmap.pivot_table(values='rmsd_final', \n",
        "                                                    index='eigen_method', \n",
        "                                                    columns='starting_point', \n",
        "                                                    aggfunc='mean')\n",
        "                \n",
        "                # Create heatmap with custom colormap\n",
        "                sns.heatmap(pivot_table, annot=True, fmt='.3f', cmap='RdYlBu_r', \n",
        "                           ax=ax1, cbar_kws={'label': 'Mean RMSD (Ã…)'})\n",
        "                ax1.set_title('1. Method Ã— Starting Point Interaction', fontweight='bold')\n",
        "                ax1.set_xlabel('Starting Point')\n",
        "                ax1.set_ylabel('Eigen Method')\n",
        "            else:\n",
        "                ax1.text(0.5, 0.5, f'Too many categories for heatmap\\\\n({n_eigen} methods Ã— {n_start} starts)', \n",
        "                        ha='center', va='center', transform=ax1.transAxes)\n",
        "                ax1.set_title('1. Method Ã— Starting Point - Too Many Categories')\n",
        "        else:\n",
        "            ax1.text(0.5, 0.5, 'Insufficient interaction data', \n",
        "                    ha='center', va='center', transform=ax1.transAxes)\n",
        "            ax1.set_title('1. Method Ã— Starting Point - Data Not Available')\n",
        "        \n",
        "        # 2. Integration Parameter Effects\n",
        "        ax2 = axes[0, 1]\n",
        "        param_cols = ['dt', 'max_steps']\n",
        "        available_params = [col for col in param_cols if col in df_secondary.columns and \n",
        "                           df_secondary[col].notna().sum() > 5]  # At least 5 data points\n",
        "        \n",
        "        if available_params:\n",
        "            # Focus on dt if available, otherwise max_steps\n",
        "            param = 'dt' if 'dt' in available_params else available_params[0]\n",
        "            df_param = df_secondary.dropna(subset=[param, 'eigen_method'])\n",
        "            \n",
        "            if len(df_param) > 0:\n",
        "                if param == 'dt':\n",
        "                    # Scatter plot for continuous dt values\n",
        "                    sns.scatterplot(data=df_param, x=param, y='rmsd_final', \n",
        "                                  hue='eigen_method', style='starting_point', \n",
        "                                  s=100, ax=ax2, alpha=0.8)\n",
        "                    ax2.set_xlabel('Integration Time Step (dt)')\n",
        "                else:\n",
        "                    # Box plot for discrete max_steps values\n",
        "                    sns.boxplot(data=df_param, x=param, y='rmsd_final', ax=ax2)\n",
        "                    ax2.set_xlabel('Max Steps')\n",
        "                    ax2.tick_params(axis='x', rotation=45)\n",
        "                \n",
        "                ax2.set_title(f'2. Integration Parameter Effects ({param})', fontweight='bold')\n",
        "                ax2.set_ylabel('Final RMSD (Ã…)')\n",
        "                if param == 'dt':\n",
        "                    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "            else:\n",
        "                ax2.text(0.5, 0.5, f'No valid {param} data', \n",
        "                        ha='center', va='center', transform=ax2.transAxes)\n",
        "                ax2.set_title(f'2. Parameter Effects - No {param} Data')\n",
        "        else:\n",
        "            ax2.text(0.5, 0.5, 'No integration parameter data', \n",
        "                    ha='center', va='center', transform=ax2.transAxes)\n",
        "            ax2.set_title('2. Integration Parameter Effects - Data Not Available')\n",
        "        \n",
        "        # 3. Efficiency vs Quality Trade-off\n",
        "        ax3 = axes[1, 0]\n",
        "        if ('time_taken' in df_secondary.columns and \n",
        "            df_secondary['time_taken'].notna().sum() > 5):\n",
        "            \n",
        "            df_efficiency = df_secondary.dropna(subset=['time_taken', 'eigen_method'])\n",
        "            \n",
        "            # Create efficiency scatter plot\n",
        "            scatter = sns.scatterplot(data=df_efficiency, x='time_taken', y='rmsd_final', \n",
        "                                    hue='eigen_method', style='starting_point',\n",
        "                                    s=120, ax=ax3, alpha=0.8)\n",
        "            \n",
        "            ax3.set_title('3. Efficiency vs Quality Trade-off', fontweight='bold')\n",
        "            ax3.set_xlabel('Computation Time (s)')\n",
        "            ax3.set_ylabel('Final RMSD (Ã…)')\n",
        "            \n",
        "            # Add Pareto frontier suggestion\n",
        "            ax3.axhline(y=0.1, color='red', linestyle='--', alpha=0.5, label='Success threshold')\n",
        "            ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "            \n",
        "            # Identify and highlight Pareto optimal points\n",
        "            # (Points that are both fast and accurate)\n",
        "            median_time = df_efficiency['time_taken'].median()\n",
        "            fast_and_accurate = df_efficiency[\n",
        "                (df_efficiency['time_taken'] <= median_time) & \n",
        "                (df_efficiency['rmsd_final'] <= 0.1)\n",
        "            ]\n",
        "            \n",
        "            if len(fast_and_accurate) > 0:\n",
        "                ax3.scatter(fast_and_accurate['time_taken'], fast_and_accurate['rmsd_final'], \n",
        "                           s=200, facecolors='none', edgecolors='green', linewidth=3,\n",
        "                           label='Fast & Accurate')\n",
        "        else:\n",
        "            ax3.text(0.5, 0.5, 'No timing data available', \n",
        "                    ha='center', va='center', transform=ax3.transAxes)\n",
        "            ax3.set_title('3. Efficiency Analysis - No Timing Data')\n",
        "        \n",
        "        # 4. Robustness Analysis (Consistency)\n",
        "        ax4 = axes[1, 1]\n",
        "        if len(df_secondary) > 0:\n",
        "            # Calculate coefficient of variation (std/mean) for each eigen method\n",
        "            consistency_stats = df_secondary.groupby('eigen_method')['rmsd_final'].agg([\n",
        "                'mean', 'std', 'count'\n",
        "            ]).reset_index()\n",
        "            \n",
        "            # Filter methods with enough data points\n",
        "            consistency_stats = consistency_stats[consistency_stats['count'] >= 3]\n",
        "            \n",
        "            if len(consistency_stats) > 0:\n",
        "                consistency_stats['cv'] = consistency_stats['std'] / consistency_stats['mean']\n",
        "                consistency_stats = consistency_stats.sort_values('cv')\n",
        "                \n",
        "                # Create consistency plot\n",
        "                bars = ax4.bar(range(len(consistency_stats)), consistency_stats['cv'], \n",
        "                              color='lightcoral', alpha=0.8)\n",
        "                ax4.set_xticks(range(len(consistency_stats)))\n",
        "                ax4.set_xticklabels(consistency_stats['eigen_method'], rotation=45)\n",
        "                ax4.set_title('4. Method Robustness (Lower = More Consistent)', fontweight='bold')\n",
        "                ax4.set_ylabel('Coefficient of Variation (std/mean)')\n",
        "                \n",
        "                # Add value labels on bars\n",
        "                for i, bar in enumerate(bars):\n",
        "                    height = bar.get_height()\n",
        "                    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                            f'{height:.2f}', ha='center', va='bottom', fontweight='bold')\n",
        "            else:\n",
        "                ax4.text(0.5, 0.5, 'Insufficient data for consistency analysis', \n",
        "                        ha='center', va='center', transform=ax4.transAxes)\n",
        "                ax4.set_title('4. Robustness Analysis - Insufficient Data')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print secondary insights\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SECONDARY ANALYSIS INSIGHTS\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        # Interaction effects\n",
        "        if ('eigen_method' in df_secondary.columns and 'starting_point' in df_secondary.columns):\n",
        "            df_interact = df_secondary.dropna(subset=['eigen_method', 'starting_point'])\n",
        "            if len(df_interact) > 0:\n",
        "                print(f\"\\nðŸ”„ INTERACTION EFFECTS:\")\n",
        "                best_combos = df_interact.groupby(['eigen_method', 'starting_point'])['rmsd_final'].mean().nsmallest(5)\n",
        "                for i, ((method, start), rmsd) in enumerate(best_combos.items()):\n",
        "                    print(f\"  {i+1}. {method:10s} + {start:15s}: {rmsd:.4f} Ã…\")\n",
        "        \n",
        "        # Parameter optimization\n",
        "        if available_params:\n",
        "            param = 'dt' if 'dt' in available_params else available_params[0]\n",
        "            df_param_opt = df_secondary.dropna(subset=[param])\n",
        "            if len(df_param_opt) > 0:\n",
        "                print(f\"\\nâš™ï¸  PARAMETER OPTIMIZATION ({param.upper()}):\")\n",
        "                param_performance = df_param_opt.groupby(param)['rmsd_final'].agg(['mean', 'count'])\n",
        "                param_performance = param_performance[param_performance['count'] >= 2]  # At least 2 samples\n",
        "                if len(param_performance) > 0:\n",
        "                    best_param = param_performance['mean'].idxmin()\n",
        "                    print(f\"  â€¢ Best {param}: {best_param} (mean RMSD: {param_performance.loc[best_param, 'mean']:.4f} Ã…)\")\n",
        "        \n",
        "        # Efficiency insights\n",
        "        if 'time_taken' in df_secondary.columns:\n",
        "            df_timing = df_secondary.dropna(subset=['time_taken', 'eigen_method'])\n",
        "            if len(df_timing) > 0:\n",
        "                print(f\"\\nâš¡ EFFICIENCY INSIGHTS:\")\n",
        "                efficiency_stats = df_timing.groupby('eigen_method').agg({\n",
        "                    'time_taken': 'mean',\n",
        "                    'rmsd_final': ['mean', lambda x: (x < 0.1).mean() * 100]\n",
        "                }).round(3)\n",
        "                efficiency_stats.columns = ['mean_time', 'mean_rmsd', 'success_rate']\n",
        "                efficiency_stats['efficiency_score'] = efficiency_stats['success_rate'] / efficiency_stats['mean_time']\n",
        "                \n",
        "                top_efficient = efficiency_stats.nlargest(3, 'efficiency_score')\n",
        "                for i, (method, stats) in enumerate(top_efficient.iterrows()):\n",
        "                    print(f\"  {i+1}. {method:12s}: {stats['efficiency_score']:.3f} (success/time ratio)\")\n",
        "    \n",
        "    else:\n",
        "        print(\"No valid data for secondary analysis plots\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Advanced Analysis: Practical Decision Making\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (len(summary_files) > 0 or len(results_files) > 0) and 'rmsd_final' in df_clean.columns:\n",
        "    df_advanced = df_clean.dropna(subset=['rmsd_final', 'eigen_method'])\n",
        "    \n",
        "    if len(df_advanced) > 0:\n",
        "        # ADVANCED ANALYSIS: RECOMMENDATION SYSTEM\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n",
        "        fig.suptitle('GAD Advanced Analysis: Practical Decision Making', fontsize=18, fontweight='bold')\n",
        "        \n",
        "        # Calculate recommendation scores for each eigen method\n",
        "        method_stats = df_advanced.groupby('eigen_method').agg({\n",
        "            'rmsd_final': ['mean', 'median', 'std', 'count', lambda x: (x < 0.1).mean()]\n",
        "        }).round(4)\n",
        "        \n",
        "        method_stats.columns = ['mean_rmsd', 'median_rmsd', 'std_rmsd', 'count', 'success_rate']\n",
        "        method_stats = method_stats[method_stats['count'] >= 2]  # At least 2 samples\n",
        "        \n",
        "        if len(method_stats) > 0:\n",
        "            # 1. Recommendation Score Calculation\n",
        "            ax1 = axes[0, 0]\n",
        "            \n",
        "            # Normalize metrics (lower RMSD and higher success rate are better)\n",
        "            method_stats['norm_median'] = 1 - (method_stats['median_rmsd'] - method_stats['median_rmsd'].min()) / (method_stats['median_rmsd'].max() - method_stats['median_rmsd'].min() + 1e-8)\n",
        "            method_stats['norm_success'] = method_stats['success_rate']\n",
        "            method_stats['norm_consistency'] = 1 - (method_stats['std_rmsd'] - method_stats['std_rmsd'].min()) / (method_stats['std_rmsd'].max() - method_stats['std_rmsd'].min() + 1e-8)\n",
        "            \n",
        "            # Add timing if available\n",
        "            if 'time_taken' in df_advanced.columns:\n",
        "                timing_stats = df_advanced.groupby('eigen_method')['time_taken'].mean()\n",
        "                method_stats = method_stats.join(timing_stats, how='left')\n",
        "                method_stats['time_taken'] = method_stats['time_taken'].fillna(method_stats['time_taken'].median())\n",
        "                method_stats['norm_speed'] = 1 - (method_stats['time_taken'] - method_stats['time_taken'].min()) / (method_stats['time_taken'].max() - method_stats['time_taken'].min() + 1e-8)\n",
        "                \n",
        "                # Weighted recommendation score\n",
        "                method_stats['recommendation_score'] = (\n",
        "                    0.35 * method_stats['norm_success'] +      # 35% success rate\n",
        "                    0.25 * method_stats['norm_median'] +       # 25% median performance  \n",
        "                    0.20 * method_stats['norm_speed'] +        # 20% speed\n",
        "                    0.20 * method_stats['norm_consistency']     # 20% consistency\n",
        "                )\n",
        "            else:\n",
        "                # Without timing data\n",
        "                method_stats['recommendation_score'] = (\n",
        "                    0.40 * method_stats['norm_success'] +      # 40% success rate\n",
        "                    0.35 * method_stats['norm_median'] +       # 35% median performance\n",
        "                    0.25 * method_stats['norm_consistency']     # 25% consistency\n",
        "                )\n",
        "            \n",
        "            # Plot recommendation scores\n",
        "            sorted_methods = method_stats.sort_values('recommendation_score', ascending=True)\n",
        "            bars = ax1.barh(range(len(sorted_methods)), sorted_methods['recommendation_score'], \n",
        "                           color='lightgreen', alpha=0.8)\n",
        "            ax1.set_yticks(range(len(sorted_methods)))\n",
        "            ax1.set_yticklabels(sorted_methods.index)\n",
        "            ax1.set_title('1. Overall Recommendation Score', fontweight='bold')\n",
        "            ax1.set_xlabel('Recommendation Score (Higher = Better)')\n",
        "            \n",
        "            # Add score labels\n",
        "            for i, bar in enumerate(bars):\n",
        "                width = bar.get_width()\n",
        "                ax1.text(width + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "                        f'{width:.3f}', ha='left', va='center', fontweight='bold')\n",
        "        \n",
        "        # 2. Performance Radar Chart (for top 3 methods)\n",
        "        ax2 = axes[0, 1]\n",
        "        if len(method_stats) >= 3:\n",
        "            top_3_methods = method_stats.nlargest(3, 'recommendation_score')\n",
        "            \n",
        "            # Radar chart data\n",
        "            categories = ['Success\\\\nRate', 'Accuracy\\\\n(low RMSD)', 'Consistency', 'Speed']\n",
        "            if 'time_taken' not in df_advanced.columns:\n",
        "                categories = categories[:-1]  # Remove speed if no timing data\n",
        "            \n",
        "            # Create radar chart\n",
        "            angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
        "            angles += angles[:1]  # Complete the circle\n",
        "            \n",
        "            colors = ['red', 'blue', 'green']\n",
        "            for i, (method, stats) in enumerate(top_3_methods.iterrows()):\n",
        "                values = [stats['norm_success'], stats['norm_median'], stats['norm_consistency']]\n",
        "                if 'norm_speed' in stats:\n",
        "                    values.append(stats['norm_speed'])\n",
        "                values += values[:1]  # Complete the circle\n",
        "                \n",
        "                ax2.plot(angles, values, 'o-', linewidth=2, label=method, color=colors[i], alpha=0.8)\n",
        "                ax2.fill(angles, values, alpha=0.1, color=colors[i])\n",
        "            \n",
        "            ax2.set_xticks(angles[:-1])\n",
        "            ax2.set_xticklabels(categories)\n",
        "            ax2.set_ylim(0, 1)\n",
        "            ax2.set_title('2. Top 3 Methods Performance Profile', fontweight='bold')\n",
        "            ax2.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
        "            ax2.grid(True)\n",
        "        else:\n",
        "            ax2.text(0.5, 0.5, 'Need at least 3 methods for radar chart', \n",
        "                    ha='center', va='center', transform=ax2.transAxes)\n",
        "            ax2.set_title('2. Performance Profile - Insufficient Methods')\n",
        "        \n",
        "        # 3. Decision Matrix\n",
        "        ax3 = axes[1, 0]\n",
        "        if len(method_stats) > 0:\n",
        "            # Create decision matrix heatmap\n",
        "            decision_cols = ['success_rate', 'median_rmsd', 'std_rmsd']\n",
        "            if 'time_taken' in method_stats.columns:\n",
        "                decision_cols.append('time_taken')\n",
        "            \n",
        "            decision_matrix = method_stats[decision_cols].copy()\n",
        "            decision_matrix.columns = ['Success Rate', 'Median RMSD', 'Std RMSD', 'Mean Time'] if 'time_taken' in method_stats.columns else ['Success Rate', 'Median RMSD', 'Std RMSD']\n",
        "            \n",
        "            # Normalize for heatmap (green = good, red = bad)\n",
        "            normalized_matrix = decision_matrix.copy()\n",
        "            normalized_matrix['Success Rate'] = decision_matrix['Success Rate']  # Higher is better\n",
        "            normalized_matrix['Median RMSD'] = 1 - (decision_matrix['Median RMSD'] - decision_matrix['Median RMSD'].min()) / (decision_matrix['Median RMSD'].max() - decision_matrix['Median RMSD'].min() + 1e-8)  # Lower is better\n",
        "            normalized_matrix['Std RMSD'] = 1 - (decision_matrix['Std RMSD'] - decision_matrix['Std RMSD'].min()) / (decision_matrix['Std RMSD'].max() - decision_matrix['Std RMSD'].min() + 1e-8)  # Lower is better\n",
        "            if 'Mean Time' in normalized_matrix.columns:\n",
        "                normalized_matrix['Mean Time'] = 1 - (decision_matrix['Mean Time'] - decision_matrix['Mean Time'].min()) / (decision_matrix['Mean Time'].max() - decision_matrix['Mean Time'].min() + 1e-8)  # Lower is better\n",
        "            \n",
        "            sns.heatmap(normalized_matrix, annot=decision_matrix, fmt='.3f', \n",
        "                       cmap='RdYlGn', ax=ax3, cbar_kws={'label': 'Normalized Score (Green = Better)'})\n",
        "            ax3.set_title('3. Decision Matrix (Annotated with Raw Values)', fontweight='bold')\n",
        "            ax3.set_xlabel('Performance Metrics')\n",
        "            ax3.set_ylabel('Eigen Methods')\n",
        "        \n",
        "        # 4. Practical Recommendations\n",
        "        ax4 = axes[1, 1]\n",
        "        ax4.axis('off')  # Remove axes for text display\n",
        "        \n",
        "        # if len(method_stats) > 0:\n",
        "        #     # Generate practical recommendations\n",
        "        #     best_overall = method_stats.loc[method_stats['recommendation_score'].idxmax()]\n",
        "        #     best_accuracy = method_stats.loc[method_stats['median_rmsd'].idxmin()]\n",
        "        #     best_reliability = method_stats.loc[method_stats['success_rate'].idxmax()]\n",
        "        #     most_consistent = method_stats.loc[method_stats['std_rmsd'].idxmin()]\n",
        "            \n",
        "        #     recommendations_text = f\\\"\\\"\\\"PRACTICAL RECOMMENDATIONS\\n\\nðŸ† BEST OVERALL: {best_overall.name}\\n   Score: {best_overall['recommendation_score']:.3f}\\n   Success: {best_overall['success_rate']*100:.1f}%\\n   Median RMSD: {best_overall['median_rmsd']:.4f} Ã…\\n\\nðŸŽ¯ MOST ACCURATE: {best_accuracy.name}\\n   Median RMSD: {best_accuracy['median_rmsd']:.4f} Ã…\\n   Success: {best_accuracy['success_rate']*100:.1f}%\\n\\nðŸ”’ MOST RELIABLE: {best_reliability.name}\\n   Success Rate: {best_reliability['success_rate']*100:.1f}%\\n   Median RMSD: {best_reliability['median_rmsd']:.4f} Ã…\\n\\nðŸ“Š MOST CONSISTENT: {most_consistent.name}\\n   Std Dev: {most_consistent['std_rmsd']:.4f} Ã…\\n   Success: {most_consistent['success_rate']*100:.1f}%\\\"\\\"\\\"\\n            \\n            if 'time_taken' in method_stats.columns:\\n                fastest = method_stats.loc[method_stats['time_taken'].idxmin()]\\n                recommendations_text += f\\\"\\\"\\\"\\\\n\\\\nâš¡ FASTEST: {fastest.name}\\\\n   Time: {fastest['time_taken']:.2f} s\\\\n   Success: {fastest['success_rate']*100:.1f}%\\\"\\\"\\\"\\n            \\n            ax4.text(0.05, 0.95, recommendations_text, transform=ax4.transAxes, \\n                    fontsize=11, verticalalignment='top', fontfamily='monospace',\\n                    bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))\\n            \\n            ax4.set_title('4. Practical Recommendations', fontweight='bold', y=0.98)\\n        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gad",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
